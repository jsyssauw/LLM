{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Metaprompting with o1\n",
    "\n",
    "Optimizing to production is one of the biggest painpoints we've seen developers experience with working with LLMs - with so much guidance for prompt engineering, RAG and fine-tuning out there, figuring out which optimization you need to hill-climb on your evals can be a difficult problem to frame and solve.\n",
    "Luckily, it appears to be one of the use cases that o1 is capable at. In this session we'll focus on how to use o1-mini to work with a set of evals to optimize our prompt for the task and improve score on our evals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functionDefinitions import TOOLS\n",
    "import csv\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "client = OpenAI()\n",
    "GPT_MODEL= 'gpt-4o-mini'\n",
    "#O1_MODEL= 'o1-mini'\n",
    "O1_MODEL='o1-2024-12-11'\n",
    "O3_MODEL= 'o3-mini-2025-01-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redlines import Redlines\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def compare_strings(string1, string2):\n",
    "    # Create a Redlines object to compare the strings\n",
    "    diff = Redlines(string1, string2)\n",
    "    \n",
    "    # Display the differences using Markdown\n",
    "    display(Markdown(diff.output_markdown))\n",
    "\n",
    "# Example usage\n",
    "string_a = \"This is the original text for comparison purposes.\"\n",
    "string_b = \"This is the modified text to compare for differences.\"\n",
    "\n",
    "compare_strings(string_a, string_b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
